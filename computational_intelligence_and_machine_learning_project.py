# -*- coding: utf-8 -*-
"""Computational Intelligence and Machine Learning Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CLFd1gt8hR-oafrWdgA_sV24Gvok26WC

#Elective Course: Computational Intelligence and Machine Learning  
### University of Patras

Author: Kristian Louka, Computer Engineering and Informatics Department, CEID Upatras. (up1072625@ac.upatras.gr)

###Project 2023-2024 Part A: Temporal Analysis of Ancient Inscriptions using Neural Networks

###Properties of this Notebook (Google Collab)
"""

import platform
print("System Information:")
print("Python Version:", platform.python_version())
print("OS:", platform.system())
print("Processor Architecture:", platform.processor())

"""### Some general information:
The provided file "iphi2802.csv" containing all the data used for this project.

## Part A1: Preprocessing and Preparing the data

###Importing the libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf

"""###Importing the dataset"""

df = pd.read_csv('iphi2802.csv', delimiter='\t')
#Dataset recognizes the tab (\t) as the delimiter and not comma (,)

df.head()

descr = df.describe(include='all')
descr

"""###Tokenization and Vectorization"""

#########################################
from sklearn.feature_extraction.text import TfidfVectorizer

#TfidfVectorizer for TF-IDF encoding with max_features (tokens) set to 1000
tfidf_vectorizer = TfidfVectorizer(max_features=1000)

# Alternatively, -> 2000
# tfidf_vectorizer = TfidfVectorizer(max_features=2000)

# Fit and transform the text column to create the TF-IDF matrix
token_tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])

# Print the shape of the TF-IDF matrix ====>> (2802 => number of documents(=rows), 1000 => number of unique tokens)
print("Shape of TF-IDF matrix:", token_tfidf_matrix.shape)

# Optionally, convert TF-IDF matrix to a DataFrame for better readability
tfidf_df = pd.DataFrame(token_tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

# Display the TF-IDF DataFrame
print(tfidf_df.head())

# Get the vocabulary (tokens) generated by the TfidfVectorizer
tokens = tfidf_vectorizer.get_feature_names_out()

# Print the total number of tokens
print("Total number of tokens:", len(tokens))

tfidf_df.describe()

"""###Normalization or Min-Max Scaling

####Our tdidf_df is already 'normalized', so we continue to search in our dataset for columns that need to be normalized.
"""

# Select numerical columns
numerical_columns = df.select_dtypes(include=['int', 'float']).columns

# Check range of values for numerical columns
for column in numerical_columns:
    column_values = df[column]
    min_value = column_values.min()
    max_value = column_values.max()
    print(f"Column '{column}': Min={min_value}, Max={max_value}")

# We proceed to normalise the region_main_id, region_sub_id, date_min and date_max columns with the MinMaxScaler method.
from sklearn.preprocessing import MinMaxScaler

# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform 'region_main_id' , 'region_sub_id' ,  'date_min' and 'date_max' columns
df[['region_main_id','region_sub_id','date_min', 'date_max']] = scaler.fit_transform(df[['region_main_id','region_sub_id','date_min', 'date_max']])

#checking if the minmaxscaler is applied:
df

tfidf_df

df['date_approx'] = df[['date_min', 'date_max']].mean(axis=1)
df

tfidf_df

# Create a new DataFrame with selected columns
X2 = df[['region_main_id', 'region_sub_id']].copy()

# Display the new DataFrame
print(X2)

# Concatenate X and tf_idf_df along the columns axis
X= pd.concat([X2, tfidf_df], axis=1, join='inner')

# Display the new DataFrame with tokens
print(X)
X.describe()
#[df1, df2, df3, ...]: A list of dataframes to concatenate.
#axis: Specifies the axis along which to concatenate. axis=0 means we concatenate along the rows (i.e., stack vertically),
  #while axis=1 means we concatenate along the columns (i.e., stack horizontally).
#join: Specifies how to handle columns that are not present in all dataframes. join='outer' means we include all columns in the output dataframe,
  # nd missing values are filled with NaN. join='inner' means we only include columns that are present in all dataframes.

Y = df.iloc[:,-1].values
print(Y)

X

"""###**Dataset info**
X = input (2802 x 1002)

Y = output (dependent variable)

###Splitting the dataset into Training Set and Test Set ---  Cross-Validation
"""

from sklearn.model_selection import KFold
# Split the data to training and testing data 5-Fold
kfold = KFold(n_splits=5, shuffle=True, random_state=0)
rmseList = []
rrseList = []

"""##Part A2: Architecture Selection"""

print(X)

"""### a-c **Activation Functions**

###Hidden Layer  
For our neural network, we will employ two types of activation functions. The first will be used in the hidden layer, and the second in the output layer.

Based on our literature review and experimental results, particularly considering their impact on error, we will use the ReLU function for the hidden layer as it is regarded as the best and most popular choice. ReLU introduces non-linearity into our model, allowing it to learn more complex patterns.

Furthermore, ReLU is computationally efficient due to its simplicity. It doesn't involve expensive operations like exponentiation, making it faster to compute than sigmoid or tanh.

While there is no literature conclusively proving that ReLU is indeed the best choice, based on experiments, competitions - challenges, and experience, we conclude that it is the most favored option.

###Ouput Layer
In general, the choice of the activation function for the output layer significantly depends on the problem our model aims to solve. In our case, we will utilize the linear activation function as we seek to predict the value of the "date_approx," a property we derived from "date_min" and "date_max" and defined as the dependent variable. Its values range continuously between 0 and 1, indicating that we are dealing with a regression problem.

The two options we dismissed are the sigmoid function, which is popular for binary classification problems, and the softmax function, which essentially generalizes the former and is preferred for multi-class classification tasks.
"""

#X = input
#Y = output (dependent variable)

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.optimizers import SGD
from keras import backend as K

import matplotlib.pyplot as plt
import numpy as np

# Convert dataframe to a Numpy Array
#X = X.values

for i, (train, test) in enumerate(kfold.split(X)):
    # Create model
    model = Sequential()

    model.add(Dense(6, activation="relu", input_dim=1002))
    model.add(Dense(1, activation="linear"))  # Linear activation for regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))
    #optimizer = Adam(learning_rate=0.001)
    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model
    model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0)

    # Evaluate model
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    print("Fold :", i, " RMSE:", scores[1])

print("RMSE: ", np.mean(rmseList))

"""###d. Experimenting on the number of nodes in the hidden layer, and plotting them (RMSE vs Epochs) based on test data

1. As the number of nodes increases, the RMSE decreases. Thus, we achieve better prediction accuracy when using more nodes in the hidden layer.
2. However, this increase in nodes leads to a significant increase in the model's execution time, as more time is required to train the parameters of the nodes.
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
from keras import backend as K

# Initialize lists to store RMSE values for each fold
rmseList = []
all_rmse = []

# Define number of folds for cross-validation
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)

# Iterate over each fold
for i, (train, test) in enumerate(kfold.split(X)):
    # Create model
    model = Sequential()
    model.add(Dense(1002, activation="relu", input_dim=1002))
    model.add(Dense(1, activation="linear"))  # Linear activation for regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))

    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model
    history = model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0, validation_data=(X[test], Y[test]))

    # Evaluate model on test data
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    all_rmse.append(history.history['rmse'])

# Plot RMSE over epochs for all folds
for i, rmse_data in enumerate(all_rmse):
    plt.plot(rmse_data, label=f'Fold {i+1} RMSE')

plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.title('RMSE vs. Epochs')
plt.legend()
plt.show()

# Display the mean RMSE across all folds
print("Mean RMSE:", np.mean(rmseList))

"""###e.Inserting hidden layers and experimenting on the number of the nodes within them.
A comprehensive response to this question, I believe, could stand as an assignment on its own. However, through experimentation with the number of nodes, we have drawn some conclusions.

In general, there are three scenarios:

1. Same number of nodes.
2. Decreasing number of nodes as the hidden layers increase.
3. Increasing number of nodes as the layers increase.

In the first case, we understand that this technique leads to a balanced model, without excessive complexity.

Our work falls into the third scenario, where increasing the nodes results in improved execution time and nearly the same error.

Moving on to adding an extra hidden layer (total of three hidden layers), by adding more hidden layers, we enhance the model's ability to comprehend or learn more complex patterns in our data. However, the risk of overfitting increases significantly.
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
from keras import backend as K

# Initialize lists to store RMSE values for each fold
rmseList = []
all_rmse = []

# Define number of folds for cross-validation
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)
X=X.values
# Iterate over each fold
for i, (train, test) in enumerate(kfold.split(X)):
    # Create model
    model = Sequential()
    model.add(Dense(25, activation="relu", input_dim=1002)) #First Hidden Layer
    model.add(Dense(16, activation="relu")) #Second Hidden Layer
    model.add(Dense(86, activation="relu")) #Third Hidden Layer
    model.add(Dense(1, activation="linear"))  # Linear Activation for Regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))

    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model
    history = model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0, validation_data=(X[test], Y[test]))

    # Evaluate model on test data
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    all_rmse.append(history.history['rmse'])

#Plot RMSE over epochs for all folds
for i, rmse_data in enumerate(all_rmse):
    plt.plot(rmse_data, label=f'Fold {i+1} RMSE')

plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.title('RMSE vs. Epochs')
plt.legend()
plt.show()

#Display the mean RMSE across all folds
print("Mean RMSE:", np.mean(rmseList))

"""###st. Stopping Criteria

The training of the neural network is completed when one of the termination criteria of the algorithm is satisfied. (in each fold independently).
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
from keras.callbacks import EarlyStopping
from keras import backend as K


# Initialize lists to store RMSE values for each fold
rmseList = []
all_rmse = []

# Define number of folds for cross-validation
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)

# Iterate over each fold
for i, (train, test) in enumerate(kfold.split(X)):
    # Define early stopping criteria for this fold
    early_stopping = EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True)

    # Create model
    model = Sequential()
    model.add(Dense(15, activation="relu", input_dim=1002)) #First Hidden Layer
    model.add(Dense(160, activation="relu")) #Second Hidden Layer
    model.add(Dense(45, activation="relu")) #Third Hidden Layer
    model.add(Dense(1, activation="linear"))  # Linear Activation for Regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))

    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model with early stopping
    history = model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0,
                        validation_data=(X[test], Y[test]), callbacks=[early_stopping])

    # Evaluate model on test data
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    all_rmse.append(history.history['rmse'])

    # Plot RMSE over epochs for this fold
    plt.plot(history.history['rmse'], label=f'Fold {i+1} RMSE')

plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.title('RMSE vs. Epochs')
plt.legend()
plt.show()

# Display the mean RMSE across all folds
print("Mean RMSE:", np.mean(rmseList))

"""##Part A3: Changing the Learning Rate and Momentum Constant"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
from keras.callbacks import EarlyStopping
from keras import backend as K

# Initialize lists to store RMSE values for each fold
rmseList = []
all_rmse = []

# Define number of folds for cross-validation
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)

# Iterate over each fold
for i, (train, test) in enumerate(kfold.split(X)):

    # Define early stopping criteria for this fold
    early_stopping = EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True)

    # Create model
    model = Sequential()
    model.add(Dense(15, activation="relu", input_dim=1002)) #First Hidden Layer
    model.add(Dense(160, activation="relu")) #Second Hidden Layer
    model.add(Dense(45, activation="relu")) #Third Hidden Layer
    model.add(Dense(1, activation="linear"))  # Linear Activation for Regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))

    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model with early stopping
    history = model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0,
                        validation_data=(X[test], Y[test]), callbacks=[early_stopping])

    # Evaluate model on test data
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    all_rmse.append(history.history['rmse'])

    # Plot RMSE over epochs for this fold
    plt.plot(history.history['rmse'], label=f'Fold {i+1} RMSE')

plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.title('RMSE vs. Epochs')
plt.legend()
plt.show()

# Display the mean RMSE across all folds
print("Mean RMSE:", np.mean(rmseList))

"""###**Grid Search**
Exhaustive search over specified parameter values for an estimator.

The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.

Due to some crucial errors in sk library (we can also verify it from the web as a lot of people are facing the same error) we do not proceed with this usefull method.

##Part A4: Regularization
A way to avoid overfitting using Dropout Technique by Keras.
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import SGD
from keras.callbacks import EarlyStopping
from keras import backend as K

# Initialize lists to store RMSE values for each fold
rmseList = []
all_rmse = []

# Define number of folds for cross-validation
n_splits = 5

# Initialize KFold object
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)

# Iterate over each fold
for i, (train, test) in enumerate(kfold.split(X)):
    # Define early stopping criteria for this fold
    early_stopping = EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True)

    # Create model
    model = Sequential()
    model.add(Dense(15, activation="relu", input_dim=1002)) # First Hidden Layer
    model.add(Dropout(0.8))  # dropout rate -> rin
    model.add(Dense(160, activation="relu")) # Second Hidden Layer
    model.add(Dropout(0.2))  # dropout rate -> rh
    model.add(Dense(45, activation="relu")) # Third Hidden Layer
    model.add(Dropout(0.2))  # dropout rate -> rh
    model.add(Dense(1, activation="linear"))  # Linear Activation for Regression

    # Compile model
    def rmse(Y_true, Y_pred):
        return K.sqrt(K.mean(K.square(Y_pred - Y_true)))

    optimizer = SGD(learning_rate=0.001, momentum=0.2, nesterov=False)
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[rmse])

    # Fit model with early stopping
    history = model.fit(X[train], Y[train], epochs=500, batch_size=500, verbose=0,
                        validation_data=(X[test], Y[test]), callbacks=[early_stopping])

    # Evaluate model on test data
    scores = model.evaluate(X[test], Y[test], verbose=0)
    rmseList.append(scores[0])
    all_rmse.append(history.history['rmse'])

    # Plot RMSE over epochs for this fold
    plt.plot(history.history['rmse'], label=f'Fold {i+1} RMSE')

plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.title('RMSE vs. Epochs')
plt.legend()
plt.show()

# Display the mean RMSE across all folds
print("Mean RMSE:", np.mean(rmseList))

"""## End of the Project.
###Thank you for your time. Part B is cooming soon! ðŸŽ‰ðŸŽ‰ðŸŽ‰
"""